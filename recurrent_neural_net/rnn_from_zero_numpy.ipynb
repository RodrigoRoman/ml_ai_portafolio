{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodrigoRoman/ml_ai_portafolio/blob/main/recurrent_neural_net/rnn_from_zero_numpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Recurrent Neural Network Language Model Using Numpy</h1>\n",
        "<h3>A Ground-Up Approach</h3>\n",
        "<p>This project seeks to build a basic language model using newspaper articles, constructing a dictionary for word indexing. Entirely coded with numpy for clarity in the underlying mathematical processes, the model generates word embeddings that elucidate complex word relationships. The model faces limitations such as the vanishing gradient issue, which constrains the training to a limited set of articles. This self-contained approach offers insight into language model mechanics and neural network training subtleties.</p>"
      ],
      "metadata": {
        "id": "fJlqZunXO-q1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "YfggciPabkvw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "hHn3wpyVcGsW"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>We need access to a file that is located in my GDrive. The file is set public, so you can download it and just change the route below as needed.</p>\n",
        "<p>The link to the file is the following: https://drive.google.com/file/d/1JhKE-1NJKM033tOf8OYoN3vwvoydHhVK/view?usp=drive_link</p>"
      ],
      "metadata": {
        "id": "nNwBVO9_p8zl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "news_s_path = \"/content/drive/MyDrive/newsSpace\""
      ],
      "metadata": {
        "id": "jMmAg5sRcMqY"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Data Preprocessing Functions</h2>\n",
        "<h3>Data cleaning</h3>\n",
        "<p>We focus on extracting the text of each article and segmenting it into individual words in order to create our word dictionary. During this process, we also refine each word by removing any special characters and converting them to lowercase. This ensures a standardized and clean dataset for our model, facilitating more effective training and analysis.</p>"
      ],
      "metadata": {
        "id": "u8JoKnYNccN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def is_url(s):\n",
        "    # A simple regex to check for a basic URL structure\n",
        "    return re.match(r'https?://', s) is not None\n",
        "def tokenize_article(line):\n",
        "  url_index = next((i for i, item in enumerate(line) if is_url(item)), None)\n",
        "  if url_index is not None:\n",
        "    return re.split(r'[ ,.;:!?()]+', ' '.join(line[url_index+1:]))\n",
        "  return None\n",
        "\n",
        "\n",
        "def process_file(filepath, num_articles):\n",
        "  articles = []\n",
        "  vocabulary = set()\n",
        "  pattern = re.compile(r'[ ,.;:!?()]+')\n",
        "  word_pattern = re.compile(r\"\\b[A-Za-z]+'?[A-Za-z]*(?=\\s|\\b)\")\n",
        "  try:\n",
        "    with open(filepath, encoding='ISO-8859-1') as file:\n",
        "      data = file.read()\n",
        "      print(data)\n",
        "      pattern = re.compile(r\"\\((Reuters|AP)\\)[\\t\\n]+(.*?)[\\t\\n]+\\d+[\\t\\n]+[0-9]{4}-[0-9]{2}-[0-9]{2}\", re.DOTALL)\n",
        "      raw_articles = pattern.findall(data)\n",
        "      print(\"amount of articles\")\n",
        "      print(len(raw_articles))\n",
        "\n",
        "      for article in raw_articles:\n",
        "        if len(articles) < num_articles:\n",
        "          article_text = article[1].strip()\n",
        "          # Cleaning and processing the article text\n",
        "          words = word_pattern.findall(article_text.lower())\n",
        "          # cleaned_article = ' '.join(words)\n",
        "          articles.append(words)\n",
        "          # Update vocabulary\n",
        "          vocabulary.update(words)\n",
        "  except IOError as e:\n",
        "    print(\"Error opening or reading the file:\", e)\n",
        "    return [], set()\n",
        "  return articles, vocabulary\n",
        "\n"
      ],
      "metadata": {
        "id": "ldt6FmxMcgkr"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Data Loading</h2>\n",
        "<p>Here we have the specific details of how many articles we will be working with</p>\n"
      ],
      "metadata": {
        "id": "EzHmh8AscXUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qyUeMjrORzY",
        "outputId": "46cdc139-917b-48ad-b2fa-3824da1d5172"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_articles = 15\n",
        "news_s_path = \"/content/drive/MyDrive/newsSpace\"\n",
        "\n",
        "data_articles, vocabulary = process_file(news_s_path, num_articles)\n",
        "print(data_articles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxUUZ59wc1jE",
        "outputId": "94ed3d6f-11d4-406b-8eaa-febb68a50c77"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amount of articles\n",
            "57469\n",
            "[['none', 'business', 'reuters', 'wall', \"street's\", 'long', 'playing', 'drama', 'waiting', 'for', 'google', 'is', 'about', 'to', 'reach', 'its', 'final', 'act', 'but', 'its', 'stock', 'market', 'debut', 'is', 'ending', 'up', 'as', 'more', 'of', 'a', 'nostalgia', 'event', 'than', 'the', 'catalyst', 'for', 'a', 'new', 'era'], ['none', 'business', 'reuters', 'short', 'sellers', 'wall', \"street's\", 'dwindling', 'band', 'of', 'ultra', 'cynics', 'are', 'seeing', 'green', 'again'], ['none', 'business', 'reuters', 'private', 'investment', 'firm', 'carlyle', 'group', 'which', 'has', 'a', 'reputation', 'for', 'making', 'well', 'timed', 'and', 'occasionally', 'controversial', 'plays', 'in', 'the', 'defense', 'industry', 'has', 'quietly', 'placed', 'its', 'bets', 'on', 'another', 'part', 'of', 'the', 'market'], ['none', 'business', 'reuters', 'soaring', 'crude', 'prices', 'plus', 'worries', 'about', 'the', 'economy', 'and', 'the', 'outlook', 'for', 'earnings', 'are', 'expected', 'to', 'hang', 'over', 'the', 'stock', 'market', 'next', 'week', 'during', 'the', 'depth', 'of', 'the', 'summer', 'doldrums'], ['none', 'business', 'reuters', 'authorities', 'have', 'halted', 'oil', 'export', 'flows', 'from', 'the', 'main', 'pipeline', 'in', 'southern', 'iraq', 'after', 'intelligence', 'showed', 'a', 'rebel', 'militia', 'could', 'strike', 'infrastructure', 'an', 'oil', 'official', 'said', 'on', 'saturday'], ['none', 'business', 'reuters', 'stocks', 'ended', 'slightly', 'higher', 'on', 'friday', 'but', 'stayed', 'near', 'lows', 'for', 'the', 'year', 'as', 'oil', 'prices', 'surged', 'past', 'a', 'barrel', 'offsetting', 'a', 'positive', 'outlook', 'from', 'computer', 'maker', 'dell', 'inc', 'dell', 'o'], ['none', 'business', 'ap', 'assets', 'of', 'the', \"nation's\", 'retail', 'money', 'market', 'mutual', 'funds', 'fell', 'by', 'billion', 'in', 'the', 'latest', 'week', 'to', 'trillion', 'the', 'investment', 'company', 'institute', 'said', 'thursday'], ['none', 'sci', 'tech', 'reuters', 'was', 'absenteeism', 'a', 'little', 'high', 'on', 'tuesday', 'among', 'the', 'guys', 'at', 'the', 'office', 'ea', 'sports', 'would', 'like', 'to', 'think', 'it', 'was', 'because', 'madden', 'nfl', 'came', 'out', 'that', 'day', 'and', 'some', 'fans', 'of', 'the', 'football', 'simulation', 'are', 'rabid', 'enough', 'to', 'take', 'a', 'sick', 'day', 'to', 'play', 'it'], ['none', 'sci', 'tech', 'reuters', 'a', 'group', 'of', 'technology', 'companies', 'including', 'texas', 'instruments', 'inc', 'txn', 'n', 'stmicroelectronics', 'stm', 'pa', 'and', 'broadcom', 'corp', 'brcm', 'o', 'on', 'thursday', 'said', 'they', 'will', 'propose', 'a', 'new', 'wireless', 'networking', 'standard', 'up', 'to', 'times', 'the', 'speed', 'of', 'the', 'current', 'generation'], ['none', 'sci', 'tech', 'reuters', 'america', 'online', 'on', 'thursday', 'said', 'it', 'plans', 'to', 'sell', 'a', 'low', 'priced', 'pc', 'targeting', 'low', 'income', 'and', 'minority', 'households', 'who', 'agree', 'to', 'sign', 'up', 'for', 'a', 'year', 'of', 'dialup', 'internet', 'service'], ['none', 'sci', 'tech', 'reuters', 'a', 'group', 'of', 'consumer', 'electronics', 'makers', 'said', 'on', 'wednesday', 'they', 'approved', 'the', 'format', 'for', 'a', 'new', 'generation', 'of', 'discs', 'that', 'can', 'store', 'five', 'times', 'the', 'data', 'of', 'dvds', 'at', 'the', 'same', 'cost', 'enough', 'to', 'put', 'a', 'full', 'season', 'of', 'the', 'sopranos', 'on', 'one', 'disc'], ['none', 'sci', 'tech', 'reuters', 'the', 'mystery', 'of', 'what', 'went', 'wrong', 'for', 'the', 'software', 'industry', 'in', 'late', 'june', 'when', 'sales', 'stalled', 'at', 'more', 'than', 'brand', 'name', 'companies', 'is', 'not', 'even', 'close', 'to', 'being', 'solved', 'although', 'the', 'third', 'quarter', 'is', 'nearly', 'halfway', 'over'], ['none', 'sci', 'tech', 'ap', 'google', 'inc', 'forged', 'ahead', 'with', 'its', 'ipo', 'auction', 'even', 'as', 'the', 'online', 'search', 'engine', 'leader', 'acknowledged', 'a', 'newly', 'published', 'magazine', 'interview', 'with', 'its', 'founders', 'contained', 'misleading', 'information'], ['none', 'sci', 'tech', 'ap', 'the', 'norwegian', 'hacker', 'famed', 'for', 'developing', 'dvd', 'encryption', 'cracking', 'software', 'has', 'apparently', 'struck', 'again', 'this', 'time', 'breaking', 'the', 'locks', 'on', 'apple', 'computer', 'inc', 's', 'wireless', 'music', 'streaming', 'technology'], ['none', 'sci', 'tech', 'reuters', 'the', 'ability', 'to', 'download', 'complete', 'tracks', 'directly', 'over', 'cell', 'phone', 'networks', 'to', 'mobile', 'phones', 'is', 'becoming', 'a', 'reality', 'in', 'europe']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check out how each article is loaded as a list\n",
        "data_articles"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2MAsecL0D1Y",
        "outputId": "532c301d-c162-46f1-e185-01708a576573"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['none',\n",
              "  'business',\n",
              "  'reuters',\n",
              "  'wall',\n",
              "  \"street's\",\n",
              "  'long',\n",
              "  'playing',\n",
              "  'drama',\n",
              "  'waiting',\n",
              "  'for',\n",
              "  'google',\n",
              "  'is',\n",
              "  'about',\n",
              "  'to',\n",
              "  'reach',\n",
              "  'its',\n",
              "  'final',\n",
              "  'act',\n",
              "  'but',\n",
              "  'its',\n",
              "  'stock',\n",
              "  'market',\n",
              "  'debut',\n",
              "  'is',\n",
              "  'ending',\n",
              "  'up',\n",
              "  'as',\n",
              "  'more',\n",
              "  'of',\n",
              "  'a',\n",
              "  'nostalgia',\n",
              "  'event',\n",
              "  'than',\n",
              "  'the',\n",
              "  'catalyst',\n",
              "  'for',\n",
              "  'a',\n",
              "  'new',\n",
              "  'era'],\n",
              " ['none',\n",
              "  'business',\n",
              "  'reuters',\n",
              "  'short',\n",
              "  'sellers',\n",
              "  'wall',\n",
              "  \"street's\",\n",
              "  'dwindling',\n",
              "  'band',\n",
              "  'of',\n",
              "  'ultra',\n",
              "  'cynics',\n",
              "  'are',\n",
              "  'seeing',\n",
              "  'green',\n",
              "  'again'],\n",
              " ['none',\n",
              "  'business',\n",
              "  'reuters',\n",
              "  'private',\n",
              "  'investment',\n",
              "  'firm',\n",
              "  'carlyle',\n",
              "  'group',\n",
              "  'which',\n",
              "  'has',\n",
              "  'a',\n",
              "  'reputation',\n",
              "  'for',\n",
              "  'making',\n",
              "  'well',\n",
              "  'timed',\n",
              "  'and',\n",
              "  'occasionally',\n",
              "  'controversial',\n",
              "  'plays',\n",
              "  'in',\n",
              "  'the',\n",
              "  'defense',\n",
              "  'industry',\n",
              "  'has',\n",
              "  'quietly',\n",
              "  'placed',\n",
              "  'its',\n",
              "  'bets',\n",
              "  'on',\n",
              "  'another',\n",
              "  'part',\n",
              "  'of',\n",
              "  'the',\n",
              "  'market'],\n",
              " ['none',\n",
              "  'business',\n",
              "  'reuters',\n",
              "  'soaring',\n",
              "  'crude',\n",
              "  'prices',\n",
              "  'plus',\n",
              "  'worries',\n",
              "  'about',\n",
              "  'the',\n",
              "  'economy',\n",
              "  'and',\n",
              "  'the',\n",
              "  'outlook',\n",
              "  'for',\n",
              "  'earnings',\n",
              "  'are',\n",
              "  'expected',\n",
              "  'to',\n",
              "  'hang',\n",
              "  'over',\n",
              "  'the',\n",
              "  'stock',\n",
              "  'market',\n",
              "  'next',\n",
              "  'week',\n",
              "  'during',\n",
              "  'the',\n",
              "  'depth',\n",
              "  'of',\n",
              "  'the',\n",
              "  'summer',\n",
              "  'doldrums'],\n",
              " ['none',\n",
              "  'business',\n",
              "  'reuters',\n",
              "  'authorities',\n",
              "  'have',\n",
              "  'halted',\n",
              "  'oil',\n",
              "  'export',\n",
              "  'flows',\n",
              "  'from',\n",
              "  'the',\n",
              "  'main',\n",
              "  'pipeline',\n",
              "  'in',\n",
              "  'southern',\n",
              "  'iraq',\n",
              "  'after',\n",
              "  'intelligence',\n",
              "  'showed',\n",
              "  'a',\n",
              "  'rebel',\n",
              "  'militia',\n",
              "  'could',\n",
              "  'strike',\n",
              "  'infrastructure',\n",
              "  'an',\n",
              "  'oil',\n",
              "  'official',\n",
              "  'said',\n",
              "  'on',\n",
              "  'saturday'],\n",
              " ['none',\n",
              "  'business',\n",
              "  'reuters',\n",
              "  'stocks',\n",
              "  'ended',\n",
              "  'slightly',\n",
              "  'higher',\n",
              "  'on',\n",
              "  'friday',\n",
              "  'but',\n",
              "  'stayed',\n",
              "  'near',\n",
              "  'lows',\n",
              "  'for',\n",
              "  'the',\n",
              "  'year',\n",
              "  'as',\n",
              "  'oil',\n",
              "  'prices',\n",
              "  'surged',\n",
              "  'past',\n",
              "  'a',\n",
              "  'barrel',\n",
              "  'offsetting',\n",
              "  'a',\n",
              "  'positive',\n",
              "  'outlook',\n",
              "  'from',\n",
              "  'computer',\n",
              "  'maker',\n",
              "  'dell',\n",
              "  'inc',\n",
              "  'dell',\n",
              "  'o'],\n",
              " ['none',\n",
              "  'business',\n",
              "  'ap',\n",
              "  'assets',\n",
              "  'of',\n",
              "  'the',\n",
              "  \"nation's\",\n",
              "  'retail',\n",
              "  'money',\n",
              "  'market',\n",
              "  'mutual',\n",
              "  'funds',\n",
              "  'fell',\n",
              "  'by',\n",
              "  'billion',\n",
              "  'in',\n",
              "  'the',\n",
              "  'latest',\n",
              "  'week',\n",
              "  'to',\n",
              "  'trillion',\n",
              "  'the',\n",
              "  'investment',\n",
              "  'company',\n",
              "  'institute',\n",
              "  'said',\n",
              "  'thursday'],\n",
              " ['none',\n",
              "  'sci',\n",
              "  'tech',\n",
              "  'reuters',\n",
              "  'was',\n",
              "  'absenteeism',\n",
              "  'a',\n",
              "  'little',\n",
              "  'high',\n",
              "  'on',\n",
              "  'tuesday',\n",
              "  'among',\n",
              "  'the',\n",
              "  'guys',\n",
              "  'at',\n",
              "  'the',\n",
              "  'office',\n",
              "  'ea',\n",
              "  'sports',\n",
              "  'would',\n",
              "  'like',\n",
              "  'to',\n",
              "  'think',\n",
              "  'it',\n",
              "  'was',\n",
              "  'because',\n",
              "  'madden',\n",
              "  'nfl',\n",
              "  'came',\n",
              "  'out',\n",
              "  'that',\n",
              "  'day',\n",
              "  'and',\n",
              "  'some',\n",
              "  'fans',\n",
              "  'of',\n",
              "  'the',\n",
              "  'football',\n",
              "  'simulation',\n",
              "  'are',\n",
              "  'rabid',\n",
              "  'enough',\n",
              "  'to',\n",
              "  'take',\n",
              "  'a',\n",
              "  'sick',\n",
              "  'day',\n",
              "  'to',\n",
              "  'play',\n",
              "  'it'],\n",
              " ['none',\n",
              "  'sci',\n",
              "  'tech',\n",
              "  'reuters',\n",
              "  'a',\n",
              "  'group',\n",
              "  'of',\n",
              "  'technology',\n",
              "  'companies',\n",
              "  'including',\n",
              "  'texas',\n",
              "  'instruments',\n",
              "  'inc',\n",
              "  'txn',\n",
              "  'n',\n",
              "  'stmicroelectronics',\n",
              "  'stm',\n",
              "  'pa',\n",
              "  'and',\n",
              "  'broadcom',\n",
              "  'corp',\n",
              "  'brcm',\n",
              "  'o',\n",
              "  'on',\n",
              "  'thursday',\n",
              "  'said',\n",
              "  'they',\n",
              "  'will',\n",
              "  'propose',\n",
              "  'a',\n",
              "  'new',\n",
              "  'wireless',\n",
              "  'networking',\n",
              "  'standard',\n",
              "  'up',\n",
              "  'to',\n",
              "  'times',\n",
              "  'the',\n",
              "  'speed',\n",
              "  'of',\n",
              "  'the',\n",
              "  'current',\n",
              "  'generation'],\n",
              " ['none',\n",
              "  'sci',\n",
              "  'tech',\n",
              "  'reuters',\n",
              "  'america',\n",
              "  'online',\n",
              "  'on',\n",
              "  'thursday',\n",
              "  'said',\n",
              "  'it',\n",
              "  'plans',\n",
              "  'to',\n",
              "  'sell',\n",
              "  'a',\n",
              "  'low',\n",
              "  'priced',\n",
              "  'pc',\n",
              "  'targeting',\n",
              "  'low',\n",
              "  'income',\n",
              "  'and',\n",
              "  'minority',\n",
              "  'households',\n",
              "  'who',\n",
              "  'agree',\n",
              "  'to',\n",
              "  'sign',\n",
              "  'up',\n",
              "  'for',\n",
              "  'a',\n",
              "  'year',\n",
              "  'of',\n",
              "  'dialup',\n",
              "  'internet',\n",
              "  'service'],\n",
              " ['none',\n",
              "  'sci',\n",
              "  'tech',\n",
              "  'reuters',\n",
              "  'a',\n",
              "  'group',\n",
              "  'of',\n",
              "  'consumer',\n",
              "  'electronics',\n",
              "  'makers',\n",
              "  'said',\n",
              "  'on',\n",
              "  'wednesday',\n",
              "  'they',\n",
              "  'approved',\n",
              "  'the',\n",
              "  'format',\n",
              "  'for',\n",
              "  'a',\n",
              "  'new',\n",
              "  'generation',\n",
              "  'of',\n",
              "  'discs',\n",
              "  'that',\n",
              "  'can',\n",
              "  'store',\n",
              "  'five',\n",
              "  'times',\n",
              "  'the',\n",
              "  'data',\n",
              "  'of',\n",
              "  'dvds',\n",
              "  'at',\n",
              "  'the',\n",
              "  'same',\n",
              "  'cost',\n",
              "  'enough',\n",
              "  'to',\n",
              "  'put',\n",
              "  'a',\n",
              "  'full',\n",
              "  'season',\n",
              "  'of',\n",
              "  'the',\n",
              "  'sopranos',\n",
              "  'on',\n",
              "  'one',\n",
              "  'disc'],\n",
              " ['none',\n",
              "  'sci',\n",
              "  'tech',\n",
              "  'reuters',\n",
              "  'the',\n",
              "  'mystery',\n",
              "  'of',\n",
              "  'what',\n",
              "  'went',\n",
              "  'wrong',\n",
              "  'for',\n",
              "  'the',\n",
              "  'software',\n",
              "  'industry',\n",
              "  'in',\n",
              "  'late',\n",
              "  'june',\n",
              "  'when',\n",
              "  'sales',\n",
              "  'stalled',\n",
              "  'at',\n",
              "  'more',\n",
              "  'than',\n",
              "  'brand',\n",
              "  'name',\n",
              "  'companies',\n",
              "  'is',\n",
              "  'not',\n",
              "  'even',\n",
              "  'close',\n",
              "  'to',\n",
              "  'being',\n",
              "  'solved',\n",
              "  'although',\n",
              "  'the',\n",
              "  'third',\n",
              "  'quarter',\n",
              "  'is',\n",
              "  'nearly',\n",
              "  'halfway',\n",
              "  'over'],\n",
              " ['none',\n",
              "  'sci',\n",
              "  'tech',\n",
              "  'ap',\n",
              "  'google',\n",
              "  'inc',\n",
              "  'forged',\n",
              "  'ahead',\n",
              "  'with',\n",
              "  'its',\n",
              "  'ipo',\n",
              "  'auction',\n",
              "  'even',\n",
              "  'as',\n",
              "  'the',\n",
              "  'online',\n",
              "  'search',\n",
              "  'engine',\n",
              "  'leader',\n",
              "  'acknowledged',\n",
              "  'a',\n",
              "  'newly',\n",
              "  'published',\n",
              "  'magazine',\n",
              "  'interview',\n",
              "  'with',\n",
              "  'its',\n",
              "  'founders',\n",
              "  'contained',\n",
              "  'misleading',\n",
              "  'information'],\n",
              " ['none',\n",
              "  'sci',\n",
              "  'tech',\n",
              "  'ap',\n",
              "  'the',\n",
              "  'norwegian',\n",
              "  'hacker',\n",
              "  'famed',\n",
              "  'for',\n",
              "  'developing',\n",
              "  'dvd',\n",
              "  'encryption',\n",
              "  'cracking',\n",
              "  'software',\n",
              "  'has',\n",
              "  'apparently',\n",
              "  'struck',\n",
              "  'again',\n",
              "  'this',\n",
              "  'time',\n",
              "  'breaking',\n",
              "  'the',\n",
              "  'locks',\n",
              "  'on',\n",
              "  'apple',\n",
              "  'computer',\n",
              "  'inc',\n",
              "  's',\n",
              "  'wireless',\n",
              "  'music',\n",
              "  'streaming',\n",
              "  'technology'],\n",
              " ['none',\n",
              "  'sci',\n",
              "  'tech',\n",
              "  'reuters',\n",
              "  'the',\n",
              "  'ability',\n",
              "  'to',\n",
              "  'download',\n",
              "  'complete',\n",
              "  'tracks',\n",
              "  'directly',\n",
              "  'over',\n",
              "  'cell',\n",
              "  'phone',\n",
              "  'networks',\n",
              "  'to',\n",
              "  'mobile',\n",
              "  'phones',\n",
              "  'is',\n",
              "  'becoming',\n",
              "  'a',\n",
              "  'reality',\n",
              "  'in',\n",
              "  'europe']]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Split data into train and test</h3>\n",
        "<p>Divide the dataset into two distinct sets: training and testing. The training set is used to teach the model, while the testing set evaluates its performance. Additionally, we organize the data into pairs of inputs and targets, where each input is a word from the text, and its corresponding target is the subsequent word. This structure is fundamental in training the model to predict the next word in a sequence based on the current word.</p>\n",
        "<p>To facilitate word processing and retrieval in our model, we establish two dictionaries. The first dictionary, known as the word-to-index dictionary, enables us to convert a given word from our corpus into its corresponding numerical index. Conversely, the second dictionary, the index-to-word dictionary, allows us to retrieve the original word from its index. These dictionaries translate between words and their numerical representations, an important process for the computational handling of text data.</p>"
      ],
      "metadata": {
        "id": "5gRIordkeLF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Preprocess articles to create input-target pairs\n",
        "def create_input_target(articles):\n",
        "  article_targets = []\n",
        "  for article in articles:\n",
        "    target_article = []\n",
        "    for i in range(len(article) - 1):\n",
        "      target_word = article[i + 1]\n",
        "      target_article.append(target_word)\n",
        "    article_targets.append(target_article)\n",
        "  return article_targets\n",
        "\n",
        "# Split data into training and test sets\n",
        "def split_data(data, test_percentage):\n",
        "  split_point = int(len(data) * test_percentage)\n",
        "  test_set = data[:split_point]\n",
        "  training_set = data[split_point:]\n",
        "  return training_set, test_set\n",
        "\n",
        "\n",
        "# Example usage\n",
        "test_percentage = 0.2\n",
        "\n",
        "# Create input-target pairs\n",
        "article_targets  = create_input_target(data_articles)\n",
        "\n",
        "# Vocabulary word-to-index and index-to-word\n",
        "word_to_idx = {ch:i for (i,ch) in enumerate(list(vocabulary))}\n",
        "idx_to_word = {i:ch for (i,ch) in enumerate(list(vocabulary))}\n",
        "\n",
        "# Take input-target as x and y\n",
        "x_train_words, x_test_words = split_data(data_articles,test_percentage)\n",
        "y_train_words, y_test_words = split_data(article_targets,test_percentage)\n",
        "\n",
        "# Change the data to their index versions\n",
        "x_train = [[word_to_idx[word] for word in article if word in word_to_idx] for article in x_train_words]\n",
        "y_train = [[word_to_idx[word] for word in article if word in word_to_idx] for article in y_train_words]\n",
        "x_test = [[word_to_idx[word] for word in article if word in word_to_idx] for article in x_test_words]\n",
        "y_test = [[word_to_idx[word] for word in article if word in word_to_idx] for article in y_test_words]\n"
      ],
      "metadata": {
        "id": "7S-h9iREemP_"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train_words[:100])\n",
        "print(y_train_words[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZGriHcAgTRw",
        "outputId": "c3b48eed-1ed7-4e81-be91-c8f9bcdb0289"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['none', 'business', 'reuters', 'soaring', 'crude', 'prices', 'plus', 'worries', 'about', 'the', 'economy', 'and', 'the', 'outlook', 'for', 'earnings', 'are', 'expected', 'to', 'hang', 'over', 'the', 'stock', 'market', 'next', 'week', 'during', 'the', 'depth', 'of', 'the', 'summer', 'doldrums'], ['none', 'business', 'reuters', 'authorities', 'have', 'halted', 'oil', 'export', 'flows', 'from', 'the', 'main', 'pipeline', 'in', 'southern', 'iraq', 'after', 'intelligence', 'showed', 'a', 'rebel', 'militia', 'could', 'strike', 'infrastructure', 'an', 'oil', 'official', 'said', 'on', 'saturday'], ['none', 'business', 'reuters', 'stocks', 'ended', 'slightly', 'higher', 'on', 'friday', 'but', 'stayed', 'near', 'lows', 'for', 'the', 'year', 'as', 'oil', 'prices', 'surged', 'past', 'a', 'barrel', 'offsetting', 'a', 'positive', 'outlook', 'from', 'computer', 'maker', 'dell', 'inc', 'dell', 'o'], ['none', 'business', 'ap', 'assets', 'of', 'the', \"nation's\", 'retail', 'money', 'market', 'mutual', 'funds', 'fell', 'by', 'billion', 'in', 'the', 'latest', 'week', 'to', 'trillion', 'the', 'investment', 'company', 'institute', 'said', 'thursday'], ['none', 'sci', 'tech', 'reuters', 'was', 'absenteeism', 'a', 'little', 'high', 'on', 'tuesday', 'among', 'the', 'guys', 'at', 'the', 'office', 'ea', 'sports', 'would', 'like', 'to', 'think', 'it', 'was', 'because', 'madden', 'nfl', 'came', 'out', 'that', 'day', 'and', 'some', 'fans', 'of', 'the', 'football', 'simulation', 'are', 'rabid', 'enough', 'to', 'take', 'a', 'sick', 'day', 'to', 'play', 'it'], ['none', 'sci', 'tech', 'reuters', 'a', 'group', 'of', 'technology', 'companies', 'including', 'texas', 'instruments', 'inc', 'txn', 'n', 'stmicroelectronics', 'stm', 'pa', 'and', 'broadcom', 'corp', 'brcm', 'o', 'on', 'thursday', 'said', 'they', 'will', 'propose', 'a', 'new', 'wireless', 'networking', 'standard', 'up', 'to', 'times', 'the', 'speed', 'of', 'the', 'current', 'generation'], ['none', 'sci', 'tech', 'reuters', 'america', 'online', 'on', 'thursday', 'said', 'it', 'plans', 'to', 'sell', 'a', 'low', 'priced', 'pc', 'targeting', 'low', 'income', 'and', 'minority', 'households', 'who', 'agree', 'to', 'sign', 'up', 'for', 'a', 'year', 'of', 'dialup', 'internet', 'service'], ['none', 'sci', 'tech', 'reuters', 'a', 'group', 'of', 'consumer', 'electronics', 'makers', 'said', 'on', 'wednesday', 'they', 'approved', 'the', 'format', 'for', 'a', 'new', 'generation', 'of', 'discs', 'that', 'can', 'store', 'five', 'times', 'the', 'data', 'of', 'dvds', 'at', 'the', 'same', 'cost', 'enough', 'to', 'put', 'a', 'full', 'season', 'of', 'the', 'sopranos', 'on', 'one', 'disc'], ['none', 'sci', 'tech', 'reuters', 'the', 'mystery', 'of', 'what', 'went', 'wrong', 'for', 'the', 'software', 'industry', 'in', 'late', 'june', 'when', 'sales', 'stalled', 'at', 'more', 'than', 'brand', 'name', 'companies', 'is', 'not', 'even', 'close', 'to', 'being', 'solved', 'although', 'the', 'third', 'quarter', 'is', 'nearly', 'halfway', 'over'], ['none', 'sci', 'tech', 'ap', 'google', 'inc', 'forged', 'ahead', 'with', 'its', 'ipo', 'auction', 'even', 'as', 'the', 'online', 'search', 'engine', 'leader', 'acknowledged', 'a', 'newly', 'published', 'magazine', 'interview', 'with', 'its', 'founders', 'contained', 'misleading', 'information'], ['none', 'sci', 'tech', 'ap', 'the', 'norwegian', 'hacker', 'famed', 'for', 'developing', 'dvd', 'encryption', 'cracking', 'software', 'has', 'apparently', 'struck', 'again', 'this', 'time', 'breaking', 'the', 'locks', 'on', 'apple', 'computer', 'inc', 's', 'wireless', 'music', 'streaming', 'technology'], ['none', 'sci', 'tech', 'reuters', 'the', 'ability', 'to', 'download', 'complete', 'tracks', 'directly', 'over', 'cell', 'phone', 'networks', 'to', 'mobile', 'phones', 'is', 'becoming', 'a', 'reality', 'in', 'europe']]\n",
            "[['business', 'reuters', 'soaring', 'crude', 'prices', 'plus', 'worries', 'about', 'the', 'economy', 'and', 'the', 'outlook', 'for', 'earnings', 'are', 'expected', 'to', 'hang', 'over', 'the', 'stock', 'market', 'next', 'week', 'during', 'the', 'depth', 'of', 'the', 'summer', 'doldrums'], ['business', 'reuters', 'authorities', 'have', 'halted', 'oil', 'export', 'flows', 'from', 'the', 'main', 'pipeline', 'in', 'southern', 'iraq', 'after', 'intelligence', 'showed', 'a', 'rebel', 'militia', 'could', 'strike', 'infrastructure', 'an', 'oil', 'official', 'said', 'on', 'saturday'], ['business', 'reuters', 'stocks', 'ended', 'slightly', 'higher', 'on', 'friday', 'but', 'stayed', 'near', 'lows', 'for', 'the', 'year', 'as', 'oil', 'prices', 'surged', 'past', 'a', 'barrel', 'offsetting', 'a', 'positive', 'outlook', 'from', 'computer', 'maker', 'dell', 'inc', 'dell', 'o'], ['business', 'ap', 'assets', 'of', 'the', \"nation's\", 'retail', 'money', 'market', 'mutual', 'funds', 'fell', 'by', 'billion', 'in', 'the', 'latest', 'week', 'to', 'trillion', 'the', 'investment', 'company', 'institute', 'said', 'thursday'], ['sci', 'tech', 'reuters', 'was', 'absenteeism', 'a', 'little', 'high', 'on', 'tuesday', 'among', 'the', 'guys', 'at', 'the', 'office', 'ea', 'sports', 'would', 'like', 'to', 'think', 'it', 'was', 'because', 'madden', 'nfl', 'came', 'out', 'that', 'day', 'and', 'some', 'fans', 'of', 'the', 'football', 'simulation', 'are', 'rabid', 'enough', 'to', 'take', 'a', 'sick', 'day', 'to', 'play', 'it'], ['sci', 'tech', 'reuters', 'a', 'group', 'of', 'technology', 'companies', 'including', 'texas', 'instruments', 'inc', 'txn', 'n', 'stmicroelectronics', 'stm', 'pa', 'and', 'broadcom', 'corp', 'brcm', 'o', 'on', 'thursday', 'said', 'they', 'will', 'propose', 'a', 'new', 'wireless', 'networking', 'standard', 'up', 'to', 'times', 'the', 'speed', 'of', 'the', 'current', 'generation'], ['sci', 'tech', 'reuters', 'america', 'online', 'on', 'thursday', 'said', 'it', 'plans', 'to', 'sell', 'a', 'low', 'priced', 'pc', 'targeting', 'low', 'income', 'and', 'minority', 'households', 'who', 'agree', 'to', 'sign', 'up', 'for', 'a', 'year', 'of', 'dialup', 'internet', 'service'], ['sci', 'tech', 'reuters', 'a', 'group', 'of', 'consumer', 'electronics', 'makers', 'said', 'on', 'wednesday', 'they', 'approved', 'the', 'format', 'for', 'a', 'new', 'generation', 'of', 'discs', 'that', 'can', 'store', 'five', 'times', 'the', 'data', 'of', 'dvds', 'at', 'the', 'same', 'cost', 'enough', 'to', 'put', 'a', 'full', 'season', 'of', 'the', 'sopranos', 'on', 'one', 'disc'], ['sci', 'tech', 'reuters', 'the', 'mystery', 'of', 'what', 'went', 'wrong', 'for', 'the', 'software', 'industry', 'in', 'late', 'june', 'when', 'sales', 'stalled', 'at', 'more', 'than', 'brand', 'name', 'companies', 'is', 'not', 'even', 'close', 'to', 'being', 'solved', 'although', 'the', 'third', 'quarter', 'is', 'nearly', 'halfway', 'over'], ['sci', 'tech', 'ap', 'google', 'inc', 'forged', 'ahead', 'with', 'its', 'ipo', 'auction', 'even', 'as', 'the', 'online', 'search', 'engine', 'leader', 'acknowledged', 'a', 'newly', 'published', 'magazine', 'interview', 'with', 'its', 'founders', 'contained', 'misleading', 'information'], ['sci', 'tech', 'ap', 'the', 'norwegian', 'hacker', 'famed', 'for', 'developing', 'dvd', 'encryption', 'cracking', 'software', 'has', 'apparently', 'struck', 'again', 'this', 'time', 'breaking', 'the', 'locks', 'on', 'apple', 'computer', 'inc', 's', 'wireless', 'music', 'streaming', 'technology'], ['sci', 'tech', 'reuters', 'the', 'ability', 'to', 'download', 'complete', 'tracks', 'directly', 'over', 'cell', 'phone', 'networks', 'to', 'mobile', 'phones', 'is', 'becoming', 'a', 'reality', 'in', 'europe']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[0])\n",
        "print(y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj22DagyipOZ",
        "outputId": "a979d5a1-972d-493b-ebd3-367d7c4cd126"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 88, 30, 61, 293, 96, 21, 253, 51, 254, 162, 234, 254, 181, 215, 161, 301, 66, 82, 294, 89, 254, 218, 130, 247, 224, 243, 254, 235, 228, 254, 261, 222]\n",
            "[88, 30, 61, 293, 96, 21, 253, 51, 254, 162, 234, 254, 181, 215, 161, 301, 66, 82, 294, 89, 254, 218, 130, 247, 224, 243, 254, 235, 228, 254, 261, 222]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>The RNN Model</h3>\n",
        "<p>This class, RNN, defines a basic recurrent neural network (RNN) for language modeling. It's initialized with parameters like hidden layer size, vocabulary size, and learning rate. The model utilizes matrices (W_e, W_y, W_h) and biases (bh, by) for computations. The softmax function converts raw scores to probabilities, while cross-entropy measures prediction accuracy. The forward pass calculates hidden states and output predictions, and the backward pass adjusts weights through gradient descent. Training involves iterating over epochs, processing input sequences, and updating model parameters based on the loss calculated from the predicted and actual next words. The model's accuracy is evaluated by comparing the predicted words with actual targets, demonstrating its ability to learn from textual data.</p>"
      ],
      "metadata": {
        "id": "vNffkVwMhkVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN:\n",
        "  def __init__(self, hidden_size,vocab_size,learning_rate):\n",
        "    self.hidden_size = hidden_size\n",
        "    self.vocab_size = vocab_size\n",
        "    # self.embedding_size = embedding_size\n",
        "    self.learning_rate = learning_rate\n",
        "\n",
        "    # Model parameters\n",
        "    self.W_e = np.random.uniform(-np.sqrt(1./vocab_size), np.sqrt(1./vocab_size), (hidden_size, vocab_size))\n",
        "    self.W_y = np.random.uniform(-np.sqrt(1./hidden_size), np.sqrt(1./hidden_size), (vocab_size, hidden_size))\n",
        "    self.W_h = np.random.uniform(-np.sqrt(1./hidden_size), np.sqrt(1./hidden_size), (hidden_size, hidden_size))\n",
        "    self.bh = np.zeros((hidden_size, 1)) # bias for hidden layer\n",
        "    self.by = np.zeros((vocab_size, 1)) # bias for output\n",
        "\n",
        "\n",
        "  # Convert values to probabilies\n",
        "  def softmax(self,x):\n",
        "    shift_x = x - np.max(x)\n",
        "    exp_shift_x = np.exp(shift_x)\n",
        "    softmax_output = exp_shift_x / np.sum(exp_shift_x)\n",
        "    return softmax_output\n",
        "\n",
        "  # Cross-entropy loss measures the difference between a predicted probability distribution and the correct distribution\n",
        "  def cross_entropy(self, probs,targets):\n",
        "    loss = 0\n",
        "    epsilon = 1e-9  # Small constant for numerical stability\n",
        "    clipping_threshold = 1e-5  # Threshold for clipping probabilities\n",
        "    for t in range(len(targets)):\n",
        "        # Clipping the probability to avoid extremely small values\n",
        "        prob = max(min(probs[t][targets[t]][0], 1 - clipping_threshold), epsilon)\n",
        "        loss += -np.log(prob)\n",
        "    return loss\n",
        "\n",
        "  # Compute the forward pass given  a series of inputs\n",
        "  # Return dictionaries for the state of embedded words, hidden layer and output layer.\n",
        "  def forward(self,inputs,hprev):\n",
        "    es,hs,ys = {},{},{}\n",
        "    ps = {i: 0 for i in range(self.vocab_size)}\n",
        "    hs[-1] = np.copy(hprev)\n",
        "    for t in range(len(inputs)):\n",
        "      es[t] = np.zeros((self.vocab_size,1))\n",
        "      es[t][inputs[t]] = 1 # one hot encoding , 1-of-k\n",
        "      hs[t] = np.tanh(np.dot(self.W_e,es[t]) + np.dot(self.W_h,hs[t-1]) + self.bh) # hidden state\n",
        "      ps[t] = np.dot(self.W_y,hs[t]) + self.by # unnormalised log probs for next char\n",
        "      ys[t] = self.softmax(ps[t])\n",
        "    return es,hs,ps,ys\n",
        "\n",
        "  # Compute backpropagation of the network\n",
        "  def backward(self,es,hs,ps,targets):\n",
        "      dW_e, dW_h, dW_y =  np.zeros_like(self.W_e),np.zeros_like(self.W_h),np.zeros_like(self.W_y)\n",
        "      dbh, dby =  np.zeros_like(self.bh),np.zeros_like(self.by)\n",
        "      dh_next = np.zeros_like(hs[0])\n",
        "      for t in reversed(range(len(targets))):\n",
        "        # Gradients\n",
        "        dy = np.copy(ps[t])\n",
        "        dy[targets[t]] -= 1\n",
        "        dW_y += np.dot(dy,hs[t].T)\n",
        "        dby += dy\n",
        "        dh = np.dot(self.W_y.T, dy) + dh_next\n",
        "        # Ouput before applying softmax\n",
        "        dh_rec = (1 - hs[t] * hs[t]) * dh\n",
        "        dbh += dh_rec\n",
        "        dW_e += np.dot(dh_rec, es[t].T)\n",
        "        dW_h += np.dot(dh_rec, hs[t-1].T)\n",
        "        dh_next = np.dot(self.W_h, dh_rec)\n",
        "      return dW_e, dW_h, dW_y, dh, dy\n",
        "\n",
        "  def update_parameters(self, dW_e, dW_h, dW_y, dbh, dby):\n",
        "    self.W_e -= self.learning_rate * dW_e\n",
        "    self.W_h -= self.learning_rate * dW_h\n",
        "    self.W_y -= self.learning_rate * dW_y\n",
        "    self.bh -= self.learning_rate * dbh\n",
        "    self.by -= self.learning_rate * dby\n",
        "\n",
        "  def train(self,x_train,y_train,epochs):\n",
        "    for epoch in range(epochs):\n",
        "      print(\"Epoch -> \", epoch)\n",
        "      rand_print =  random.randint(1, len(x_train)-1)\n",
        "      for batch_idx, inputs in enumerate(x_train):\n",
        "        total_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "        if batch_idx==0:\n",
        "          h_prev = np.zeros((self.hidden_size,1))\n",
        "        targets = y_train[batch_idx]\n",
        "        es,hs,ps,ys = self.forward(inputs, h_prev)\n",
        "        dW_e, dW_h, dW_y, dh, dy = self.backward(es, hs, ps, targets)\n",
        "        loss = self.cross_entropy(ps, targets)\n",
        "        self.update_parameters(dW_e, dW_h, dW_y, dh, dy)\n",
        "        h_prev = hs[len(inputs)-1]\n",
        "        for t in range(len(targets)):\n",
        "          predicted_index = np.argmax(ys[t])\n",
        "          correct_predictions += (predicted_index == targets[t])\n",
        "          total_predictions += 1\n",
        "        if(batch_idx == rand_print):\n",
        "          print(\"Input sentence:\")\n",
        "          print([idx_to_word[i] for i in targets])\n",
        "          print(\"Predicted:\")\n",
        "          print([idx_to_word[np.argmax(ys[i])] for i in range(len(targets))])\n",
        "          print(\"Amount of correct predictions\")\n",
        "          print(correct_predictions)\n",
        "          accuracy = correct_predictions/total_predictions\n",
        "          print(\"Accuracy -> \", accuracy)\n",
        "          print(\"Loss -> \", loss)\n"
      ],
      "metadata": {
        "id": "1nSjWhe3hi7W"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(vocabulary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXniBSQniKih",
        "outputId": "09024e19-a9cf-4204-d571-1a7873d6aa1d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "vocabulary_size = len(vocabulary)\n",
        "embedding_size = 400\n",
        "hidden_size = 1000\n",
        "rnn = RNN(hidden_size=hidden_size, vocab_size=vocabulary_size,learning_rate=0.01)\n",
        "rnn.train(x_train,y_train,epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNbuGbr_1Dru",
        "outputId": "effb7f85-920f-47b2-b5a3-fe53298c4ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch ->  0\n",
            "Input sentence:\n",
            "['sci', 'tech', 'reuters', 'a', 'group', 'of', 'consumer', 'electronics', 'makers', 'said', 'on', 'wednesday', 'they', 'approved', 'the', 'format', 'for', 'a', 'new', 'generation', 'of', 'discs', 'that', 'can', 'store', 'five', 'times', 'the', 'data', 'of', 'dvds', 'at', 'the', 'same', 'cost', 'enough', 'to', 'put', 'a', 'full', 'season', 'of', 'the', 'sopranos', 'on', 'one', 'disc']\n",
            "Predicted:\n",
            "['business', 'sci', 'reuters', 'hang', 'firm', 'business', 'the', 'occasionally', 'sci', 'are', 'halfway', 'when', 'sci', 'fans', 'a', 'struck', 'business', 'brcm', 'america', 'internet', 'even', 'ahead', 'business', 'sci', 'sci', 'stock', 'sci', 'pc', 'interview', 'business', 'the', 'halted', 'sci', 'with', 'sci', 'its', 'past', 'plays', 'than', 'contained', 'maker', 'sci', 'the', 'europe', 'playing', 'when', 'sell']\n",
            "Amount of correct predictions\n",
            "2\n",
            "Accuracy ->  0.0425531914893617\n",
            "Loss ->  453.604850481159\n",
            "Epoch ->  1\n",
            "Input sentence:\n",
            "['sci', 'tech', 'ap', 'the', 'norwegian', 'hacker', 'famed', 'for', 'developing', 'dvd', 'encryption', 'cracking', 'software', 'has', 'apparently', 'struck', 'again', 'this', 'time', 'breaking', 'the', 'locks', 'on', 'apple', 'computer', 'inc', 's', 'wireless', 'music', 'streaming', 'technology']\n",
            "Predicted:\n",
            "['sci', 'tech', 'reuters', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'retail', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci']\n",
            "Amount of correct predictions\n",
            "2\n",
            "Accuracy ->  0.06451612903225806\n",
            "Loss ->  207.03712422230413\n",
            "Epoch ->  2\n",
            "Input sentence:\n",
            "['sci', 'tech', 'reuters', 'was', 'absenteeism', 'a', 'little', 'high', 'on', 'tuesday', 'among', 'the', 'guys', 'at', 'the', 'office', 'ea', 'sports', 'would', 'like', 'to', 'think', 'it', 'was', 'because', 'madden', 'nfl', 'came', 'out', 'that', 'day', 'and', 'some', 'fans', 'of', 'the', 'football', 'simulation', 'are', 'rabid', 'enough', 'to', 'take', 'a', 'sick', 'day', 'to', 'play', 'it']\n",
            "Predicted:\n",
            "['sci', 'tech', 'reuters', 'sci', 'sci', 'sci', 'business', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'business', 'sci', 'business', 'business', 'sci', 'business', 'sci', 'sci', 'sci', 'sci', 'sci', 'business', 'sci', 'business', 'sci', 'sci', 'sci', 'sci', 'fans', 'sci', 'the', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci']\n",
            "Amount of correct predictions\n",
            "5\n",
            "Accuracy ->  0.10204081632653061\n",
            "Loss ->  185.3928416691496\n",
            "Epoch ->  3\n",
            "Input sentence:\n",
            "['sci', 'tech', 'reuters', 'the', 'ability', 'to', 'download', 'complete', 'tracks', 'directly', 'over', 'cell', 'phone', 'networks', 'to', 'mobile', 'phones', 'is', 'becoming', 'a', 'reality', 'in', 'europe']\n",
            "Predicted:\n",
            "['sci', 'tech', 'reuters', 'the', 'mystery', 'of', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci']\n",
            "Amount of correct predictions\n",
            "4\n",
            "Accuracy ->  0.17391304347826086\n",
            "Loss ->  53.56843839171914\n",
            "Epoch ->  4\n",
            "Input sentence:\n",
            "['sci', 'tech', 'ap', 'the', 'norwegian', 'hacker', 'famed', 'for', 'developing', 'dvd', 'encryption', 'cracking', 'software', 'has', 'apparently', 'struck', 'again', 'this', 'time', 'breaking', 'the', 'locks', 'on', 'apple', 'computer', 'inc', 's', 'wireless', 'music', 'streaming', 'technology']\n",
            "Predicted:\n",
            "['sci', 'tech', 'reuters', 'the', 'mystery', 'of', 'a', 'for', 'a', 'sci', 'reuters', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'norwegian', 'on', 'one', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci']\n",
            "Amount of correct predictions\n",
            "5\n",
            "Accuracy ->  0.16129032258064516\n",
            "Loss ->  73.13014138030157\n",
            "Epoch ->  5\n",
            "Input sentence:\n",
            "['sci', 'tech', 'reuters', 'america', 'online', 'on', 'thursday', 'said', 'it', 'plans', 'to', 'sell', 'a', 'low', 'priced', 'pc', 'targeting', 'low', 'income', 'and', 'minority', 'households', 'who', 'agree', 'to', 'sign', 'up', 'for', 'a', 'year', 'of', 'dialup', 'internet', 'service']\n",
            "Predicted:\n",
            "['sci', 'tech', 'reuters', 'the', 'the', 'the', 'thursday', 'said', 'on', 'plans', 'to', 'the', 'a', 'low', 'of', 'pc', 'targeting', 'low', 'income', 'and', 'minority', 'households', 'who', 'agree', 'sci', 'hang', 'a', 'for', 'a', 'year', 'of', 'the', 'internet', 'the']\n",
            "Amount of correct predictions\n",
            "23\n",
            "Accuracy ->  0.6764705882352942\n",
            "Loss ->  69.42374303869555\n",
            "Epoch ->  6\n",
            "Input sentence:\n",
            "['business', 'ap', 'assets', 'of', 'the', \"nation's\", 'retail', 'money', 'market', 'mutual', 'funds', 'fell', 'by', 'billion', 'in', 'the', 'latest', 'week', 'to', 'trillion', 'the', 'investment', 'company', 'institute', 'said', 'thursday']\n",
            "Predicted:\n",
            "['sci', 'reuters', 'the', 'of', 'the', 'summer', 'retail', 'money', 'market', 'mutual', 'funds', 'fell', 'by', 'sci', 'in', 'the', 'latest', 'week', 'to', 'trillion', 'the', 'investment', 'company', 'institute', 'said', 'on']\n",
            "Amount of correct predictions\n",
            "20\n",
            "Accuracy ->  0.7692307692307693\n",
            "Loss ->  53.775675052873055\n",
            "Epoch ->  7\n",
            "Input sentence:\n",
            "['sci', 'tech', 'ap', 'google', 'inc', 'forged', 'ahead', 'with', 'its', 'ipo', 'auction', 'even', 'as', 'the', 'online', 'search', 'engine', 'leader', 'acknowledged', 'a', 'newly', 'published', 'magazine', 'interview', 'with', 'its', 'founders', 'contained', 'misleading', 'information']\n",
            "Predicted:\n",
            "['sci', 'tech', 'reuters', 'the', 'inc', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'search', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci', 'sci']\n",
            "Amount of correct predictions\n",
            "4\n",
            "Accuracy ->  0.13333333333333333\n",
            "Loss ->  52.14856905365254\n",
            "Epoch ->  8\n",
            "Input sentence:\n",
            "['sci', 'tech', 'reuters', 'a', 'group', 'of', 'technology', 'companies', 'including', 'texas', 'instruments', 'inc', 'txn', 'n', 'stmicroelectronics', 'stm', 'pa', 'and', 'broadcom', 'corp', 'brcm', 'o', 'on', 'thursday', 'said', 'they', 'will', 'propose', 'a', 'new', 'wireless', 'networking', 'standard', 'up', 'to', 'times', 'the', 'speed', 'of', 'the', 'current', 'generation']\n",
            "Predicted:\n",
            "['sci', 'tech', 'reuters', 'the', 'group', 'of', 'the', 'companies', 'including', 'texas', 'instruments', 'inc', 'txn', 'n', 'stmicroelectronics', 'stm', 'pa', 'and', 'broadcom', 'corp', 'sci', 'o', 'on', 'thursday', 'said', 'on', 'will', 'propose', 'a', 'new', 'wireless', 'networking', 'standard', 'sci', 'to', 'times', 'the', 'data', 'of', 'the', 'summer', 'generation']\n",
            "Amount of correct predictions\n",
            "35\n",
            "Accuracy ->  0.8333333333333334\n",
            "Loss ->  69.93978897151773\n",
            "Epoch ->  9\n",
            "Input sentence:\n",
            "['sci', 'tech', 'reuters', 'a', 'group', 'of', 'consumer', 'electronics', 'makers', 'said', 'on', 'wednesday', 'they', 'approved', 'the', 'format', 'for', 'a', 'new', 'generation', 'of', 'discs', 'that', 'can', 'store', 'five', 'times', 'the', 'data', 'of', 'dvds', 'at', 'the', 'same', 'cost', 'enough', 'to', 'put', 'a', 'full', 'season', 'of', 'the', 'sopranos', 'on', 'one', 'disc']\n",
            "Predicted:\n",
            "['sci', 'tech', 'reuters', 'the', 'group', 'of', 'the', 'electronics', 'makers', 'said', 'on', 'wednesday', 'they', 'approved', 'the', 'format', 'for', 'a', 'new', 'generation', 'of', 'the', 'that', 'can', 'store', 'five', 'times', 'the', 'data', 'of', 'the', 'at', 'the', 'same', 'cost', 'enough', 'to', 'put', 'a', 'full', 'season', 'of', 'the', 'sci', 'on', 'thursday', 'disc']\n",
            "Amount of correct predictions\n",
            "41\n",
            "Accuracy ->  0.8723404255319149\n",
            "Loss ->  72.73952435286112\n",
            "Epoch ->  10\n",
            "Input sentence:\n",
            "['business', 'reuters', 'stocks', 'ended', 'slightly', 'higher', 'on', 'friday', 'but', 'stayed', 'near', 'lows', 'for', 'the', 'year', 'as', 'oil', 'prices', 'surged', 'past', 'a', 'barrel', 'offsetting', 'a', 'positive', 'outlook', 'from', 'computer', 'maker', 'dell', 'inc', 'dell', 'o']\n",
            "Predicted:\n",
            "['sci', 'reuters', 'authorities', 'ended', 'slightly', 'higher', 'on', 'friday', 'but', 'stayed', 'near', 'lows', 'for', 'the', 'year', 'of', 'oil', 'prices', 'surged', 'past', 'a', 'barrel', 'offsetting', 'a', 'positive', 'outlook', 'from', 'computer', 'maker', 'dell', 'inc', 'dell', 'o']\n",
            "Amount of correct predictions\n",
            "30\n",
            "Accuracy ->  0.9090909090909091\n",
            "Loss ->  50.681144433284985\n",
            "Epoch ->  11\n",
            "Input sentence:\n",
            "['sci', 'tech', 'reuters', 'america', 'online', 'on', 'thursday', 'said', 'it', 'plans', 'to', 'sell', 'a', 'low', 'priced', 'pc', 'targeting', 'low', 'income', 'and', 'minority', 'households', 'who', 'agree', 'to', 'sign', 'up', 'for', 'a', 'year', 'of', 'dialup', 'internet', 'service']\n",
            "Predicted:\n",
            "['sci', 'tech', 'reuters', 'the', 'online', 'on', 'thursday', 'said', 'on', 'plans', 'to', 'sell', 'a', 'low', 'priced', 'pc', 'targeting', 'low', 'income', 'and', 'minority', 'households', 'who', 'agree', 'to', 'sign', 'up', 'for', 'a', 'year', 'of', 'the', 'internet', 'service']\n",
            "Amount of correct predictions\n",
            "31\n",
            "Accuracy ->  0.9117647058823529\n",
            "Loss ->  48.114851983587656\n",
            "Epoch ->  12\n",
            "Input sentence:\n",
            "['sci', 'tech', 'reuters', 'was', 'absenteeism', 'a', 'little', 'high', 'on', 'tuesday', 'among', 'the', 'guys', 'at', 'the', 'office', 'ea', 'sports', 'would', 'like', 'to', 'think', 'it', 'was', 'because', 'madden', 'nfl', 'came', 'out', 'that', 'day', 'and', 'some', 'fans', 'of', 'the', 'football', 'simulation', 'are', 'rabid', 'enough', 'to', 'take', 'a', 'sick', 'day', 'to', 'play', 'it']\n",
            "Predicted:\n",
            "['sci', 'tech', 'reuters', 'the', 'absenteeism', 'a', 'little', 'sci', 'on', 'tuesday', 'among', 'the', 'guys', 'at', 'the', 'office', 'ea', 'sports', 'sci', 'sci', 'to', 'sci', 'it', 'was', 'because', 'madden', 'nfl', 'came', 'sci', 'that', 'day', 'and', 'some', 'fans', 'of', 'the', 'football', 'simulation', 'sci', 'sci', 'enough', 'to', 'sci', 'a', 'sick', 'day', 'to', 'sci', 'it']\n",
            "Amount of correct predictions\n",
            "39\n",
            "Accuracy ->  0.7959183673469388\n",
            "Loss ->  69.33725356200706\n",
            "Epoch ->  13\n",
            "Input sentence:\n",
            "['sci', 'tech', 'reuters', 'the', 'ability', 'to', 'download', 'complete', 'tracks', 'directly', 'over', 'cell', 'phone', 'networks', 'to', 'mobile', 'phones', 'is', 'becoming', 'a', 'reality', 'in', 'europe']\n",
            "Predicted:\n",
            "['sci', 'tech', 'reuters', 'the', 'group', 'of', 'download', 'complete', 'tracks', 'directly', 'over', 'cell', 'phone', 'networks', 'to', 'mobile', 'phones', 'is', 'becoming', 'a', 'reality', 'in', 'europe']\n",
            "Amount of correct predictions\n",
            "21\n",
            "Accuracy ->  0.9130434782608695\n",
            "Loss ->  29.34982329585518\n",
            "Epoch ->  14\n",
            "Input sentence:\n",
            "['sci', 'tech', 'reuters', 'the', 'mystery', 'of', 'what', 'went', 'wrong', 'for', 'the', 'software', 'industry', 'in', 'late', 'june', 'when', 'sales', 'stalled', 'at', 'more', 'than', 'brand', 'name', 'companies', 'is', 'not', 'even', 'close', 'to', 'being', 'solved', 'although', 'the', 'third', 'quarter', 'is', 'nearly', 'halfway', 'over']\n",
            "Predicted:\n",
            "['sci', 'tech', 'reuters', 'a', 'group', 'of', 'the', 'went', 'wrong', 'for', 'the', 'year', 'industry', 'in', 'late', 'june', 'when', 'sales', 'stalled', 'at', 'the', 'than', 'brand', 'name', 'companies', 'is', 'not', 'even', 'close', 'to', 'being', 'solved', 'although', 'the', 'third', 'quarter', 'is', 'nearly', 'halfway', 'over']\n",
            "Amount of correct predictions\n",
            "35\n",
            "Accuracy ->  0.875\n",
            "Loss ->  50.50567790097055\n",
            "Epoch ->  15\n",
            "Input sentence:\n",
            "['sci', 'tech', 'reuters', 'a', 'group', 'of', 'technology', 'companies', 'including', 'texas', 'instruments', 'inc', 'txn', 'n', 'stmicroelectronics', 'stm', 'pa', 'and', 'broadcom', 'corp', 'brcm', 'o', 'on', 'thursday', 'said', 'they', 'will', 'propose', 'a', 'new', 'wireless', 'networking', 'standard', 'up', 'to', 'times', 'the', 'speed', 'of', 'the', 'current', 'generation']\n",
            "Predicted:\n",
            "['sci', 'tech', 'reuters', 'the', 'group', 'of', 'the', 'companies', 'including', 'texas', 'instruments', 'inc', 'txn', 'n', 'stmicroelectronics', 'stm', 'pa', 'and', 'broadcom', 'corp', 'brcm', 'o', 'on', 'thursday', 'said', 'on', 'will', 'propose', 'a', 'new', 'wireless', 'networking', 'standard', 'up', 'to', 'times', 'the', 'speed', 'of', 'the', 'current', 'generation']\n",
            "Amount of correct predictions\n",
            "39\n",
            "Accuracy ->  0.9285714285714286\n",
            "Loss ->  50.470164739807295\n",
            "Epoch ->  16\n",
            "Input sentence:\n",
            "['sci', 'tech', 'reuters', 'the', 'ability', 'to', 'download', 'complete', 'tracks', 'directly', 'over', 'cell', 'phone', 'networks', 'to', 'mobile', 'phones', 'is', 'becoming', 'a', 'reality', 'in', 'europe']\n",
            "Predicted:\n",
            "['sci', 'tech', 'reuters', 'the', 'group', 'to', 'download', 'complete', 'tracks', 'directly', 'over', 'cell', 'phone', 'networks', 'to', 'mobile', 'phones', 'is', 'becoming', 'a', 'reality', 'in', 'europe']\n",
            "Amount of correct predictions\n",
            "22\n",
            "Accuracy ->  0.9565217391304348\n",
            "Loss ->  25.962750820001617\n",
            "Epoch ->  17\n",
            "Input sentence:\n",
            "['sci', 'tech', 'reuters', 'a', 'group', 'of', 'consumer', 'electronics', 'makers', 'said', 'on', 'wednesday', 'they', 'approved', 'the', 'format', 'for', 'a', 'new', 'generation', 'of', 'discs', 'that', 'can', 'store', 'five', 'times', 'the', 'data', 'of', 'dvds', 'at', 'the', 'same', 'cost', 'enough', 'to', 'put', 'a', 'full', 'season', 'of', 'the', 'sopranos', 'on', 'one', 'disc']\n",
            "Predicted:\n",
            "['sci', 'tech', 'reuters', 'the', 'group', 'of', 'the', 'electronics', 'makers', 'said', 'on', 'wednesday', 'they', 'approved', 'the', 'format', 'for', 'a', 'new', 'generation', 'of', 'the', 'that', 'can', 'store', 'five', 'times', 'the', 'data', 'of', 'the', 'at', 'the', 'same', 'cost', 'enough', 'to', 'put', 'a', 'full', 'season', 'of', 'the', 'sopranos', 'on', 'one', 'disc']\n",
            "Amount of correct predictions\n",
            "43\n",
            "Accuracy ->  0.9148936170212766\n",
            "Loss ->  51.680965014479966\n",
            "Epoch ->  18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Conclusions</h3>\n",
        "<p>Our model achieved a remarkable 100% accuracy in predicting sentences within its training data. This high accuracy, however, may not extend to unseen articles, highlighting the model's limitations in handling new data. The primary value of this exercise lies in the generation of word embeddings. These embeddings are crucial for tasks such as classifying the genre of new articles or aiding in word completion. They represent a significant step forward in context-based word representation, demonstrating the potential of our model in various natural language processing applications.</p>"
      ],
      "metadata": {
        "id": "qjQN9g3a3mVc"
      }
    }
  ]
}